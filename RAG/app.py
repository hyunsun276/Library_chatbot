# app.py
# RAG ê²€ìƒ‰ + í˜ë¥´ì†Œë‚˜ ì£¼ì… + ë‹µë³€ ìƒì„± (Streamlit Cloud ë°ëª¨ìš©)

import os, re, glob, json
import streamlit as st
import chromadb
from rank_bm25 import BM25Okapi
from openai import OpenAI
from dotenv import load_dotenv

# ================= ê¸°ë³¸ ì„¤ì • =================
load_dotenv()
oa = OpenAI()

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
MODEL         = os.getenv("MODEL", "gpt-4o")
TOP_K         = int(os.getenv("TOP_K", "6"))
SPOILER_LEVEL = int(os.getenv("SPOILER_LEVEL", "3"))
EMB_MODEL     = "text-embedding-3-small"

WORK_ID_MAP = {
    "ì§€êµ¬ ëì˜ ì˜¨ì‹¤": "jigu-ggut-onshil",
    "ì¢…ì˜ ê¸°ì›": "jong-ui-giwon",
    "ì†Œë…„ì´ ì˜¨ë‹¤": "so-nyeon-i-onda"
}

DATA_DIR = "RAG/.data"   # JSONL íŒŒì¼ ìœ„ì¹˜

# ================= DB ì´ˆê¸°í™” (InMemory) =================
client = chromadb.Client()
col = client.create_collection(name="library-demo")

def load_jsonl(path: str):
    with open(path, "r", encoding="utf-8") as f:
        return [json.loads(line) for line in f if line.strip()]

# JSONL â†’ Chroma ì—…ë¡œë“œ
def init_db():
    all_chunks = []
    for path in glob.glob(os.path.join(DATA_DIR, "*.jsonl")):
        rows = load_jsonl(path)
        for row in rows:
            txt = row.get("text") or row.get("scene_full_text") or row.get("chapter_full_text") or row.get("full_bio") or ""
            if not txt: 
                continue
            meta = row.get("metadata", {})
            meta.update({k:v for k,v in row.items() if k not in ["text"]})
            all_chunks.append((txt, meta))

    # BM25 ìš©
    docs = [txt for txt,_ in all_chunks]
    bm25 = BM25Okapi([re.sub(r"[^0-9a-zA-Zê°€-í£\s]", " ", d.lower()).split() for d in docs])

    # OpenAI ì„ë² ë”©
    embeddings = []
    for i in range(0, len(docs), 50):
        batch = docs[i:i+50]
        resp = oa.embeddings.create(model=EMB_MODEL, input=batch)
        embeddings.extend([d.embedding for d in resp.data])

    # Chromaì— ì—…ë¡œë“œ
    ids = [f"doc-{i}" for i in range(len(docs))]
    metadatas = [m for _,m in all_chunks]
    col.add(ids=ids, documents=docs, metadatas=metadatas, embeddings=embeddings)

    return bm25, dict(zip(ids, zip(docs, metadatas)))

bm25, id2doc = init_db()

# ================= ê²€ìƒ‰ =================
def reciprocal_rank_fusion(results_lists, k=60):
    scores = {}
    for res in results_lists:
        for rank, doc_id in enumerate(res, start=1):
            scores[doc_id] = scores.get(doc_id, 0) + 1.0/(k+rank)
    return sorted(scores.items(), key=lambda x: x[1], reverse=True)

def hybrid_retrieve(query, top_k, work_id=None):
    if not query.strip():
        return []
    emb = oa.embeddings.create(model=EMB_MODEL, input=query).data[0].embedding
    vec_res = col.query(query_embeddings=[emb], n_results=top_k*3,
                        where={"work_id": work_id} if work_id else None)
    vec_ids = vec_res["ids"][0] if vec_res["ids"] else []

    tokens = re.sub(r"[^0-9a-zA-Zê°€-í£\s]", " ", query.lower()).split()
    scores = bm25.get_scores(tokens)
    bm25_ids = [f"doc-{i}" for i,_ in sorted(enumerate(scores), key=lambda x: x[1], reverse=True)[:top_k*3]]

    fused = reciprocal_rank_fusion([vec_ids, bm25_ids])
    hits = []
    for did,_ in fused:
        if did not in id2doc: continue
        txt, meta = id2doc[did]
        if meta.get("spoiler_level",3) <= SPOILER_LEVEL:
            hits.append((did, txt, meta))
        if len(hits) >= top_k: break
    return hits

# ================= Prompt =================
def make_prompt(query, hits, work_id=None, speak_as=None, history=[]):
    persona_block = ""
    if speak_as and work_id:
        persos = [txt for did,(txt,meta) in id2doc.items()
                  if meta.get("work_id")==work_id and meta.get("kind") in ["persona","characters_raw"]
                  and (speak_as in meta.get("character",""))]
        if persos:
            persona_block = f"[ì¸ë¬¼ í˜ë¥´ì†Œë‚˜: {speak_as}]\n{persos[0]}"

    context_cards = []
    for _,txt,meta in hits:
        title = meta.get("scene_title") or meta.get("chapter_label") or meta.get("kind")
        context_cards.append(f"### {title}\n{txt}")

    system = (
        "ë‹¹ì‹ ì€ ì†Œì„¤ ì† ì¸ë¬¼ì˜ ë§íˆ¬ë¥¼ ì¬í˜„í•˜ëŠ” AIì…ë‹ˆë‹¤.\n"
        "ì»¨í…ìŠ¤íŠ¸ë¥¼ ê·¼ê±°ë¡œë§Œ ë‹µí•˜ì„¸ìš”.\n"
        "ëŒ€í™”í•  ë•ŒëŠ” ì¸ë¬¼ì˜ ë§íˆ¬/ê°€ì¹˜ê´€ì„ ë°˜ì˜í•´ 1~2ë¬¸ì¥ ì´ë‚´ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€ë‹µí•˜ì„¸ìš”."
    )
    if persona_block: system += "\n\n" + persona_block

    msgs = [{"role":"system","content":system}]
    if history: msgs.extend(history[-6:])
    msgs.append({"role":"user","content":f"ì§ˆë¬¸: {query}\n\n[ì»¨í…ìŠ¤íŠ¸]\n" + "\n\n".join(context_cards)})
    return msgs

def generate(messages):
    resp = oa.chat.completions.create(model=MODEL, messages=messages)
    return resp.choices[0].message.content.strip()

# ================= Streamlit UI =================
st.set_page_config(page_title="ğŸ“š ì†Œì„¤ ìºë¦­í„° ì±—ë´‡", layout="centered")

# CSS (ì¹´í†¡ ìŠ¤íƒ€ì¼)
st.markdown("""
<style>
html, body, .stApp { background-color: #CFE7FF !important; }
.chat-container { display: flex; flex-direction: column; padding: 20px; }
.user-message { background-color: #FFEB00; color: #000;
  padding: 10px 14px; border-radius: 18px 0 18px 18px; max-width: 70%;
  align-self: flex-end; margin: 6px 0 6px auto; }
.bot-message { background-color: #FFFFFF; color: #000;
  padding: 10px 14px; border-radius: 0 18px 18px 18px; max-width: 70%;
  align-self: flex-start; margin: 6px auto 6px 0; }
</style>
""", unsafe_allow_html=True)

if "history" not in st.session_state: st.session_state.history = []
if "work_id" not in st.session_state: st.session_state.work_id = None
if "speak_as" not in st.session_state: st.session_state.speak_as = None

st.title("ğŸ“š ì†Œì„¤ ì† ì¸ë¬¼ê³¼ ëŒ€í™”í•˜ê¸°")

work_kor = st.selectbox("ì‘í’ˆ ì„ íƒ", ["ì§€êµ¬ ëì˜ ì˜¨ì‹¤","ì¢…ì˜ ê¸°ì›","ì†Œë…„ì´ ì˜¨ë‹¤"])
st.session_state.work_id = WORK_ID_MAP.get(work_kor)
st.session_state.speak_as = st.text_input("ì¸ë¬¼ ì„ íƒ (ì˜ˆ: ìœ ì§„, ë™í˜¸, ì•„ì˜ ë“±)", "")

st.markdown('<div class="chat-container">', unsafe_allow_html=True)
for msg in st.session_state.history:
    cls = "user-message" if msg["role"]=="user" else "bot-message"
    st.markdown(f'<div class="{cls}">{msg["content"]}</div>', unsafe_allow_html=True)
st.markdown('</div>', unsafe_allow_html=True)

query = st.text_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”", key="input")
if st.button("ë³´ë‚´ê¸°", type="primary") and query.strip():
    hits = hybrid_retrieve(query, TOP_K, st.session_state.work_id)
    msgs = make_prompt(query, hits, st.session_state.work_id, st.session_state.speak_as, st.session_state.history)
    ans = generate(msgs)
    st.session_state.history.append({"role":"user","content":query})
    st.session_state.history.append({"role":"assistant","content":ans})
    st.rerun()
